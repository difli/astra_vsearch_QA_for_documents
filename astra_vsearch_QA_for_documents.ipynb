{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pg-sys/astra_vsearch_QA_for_documents/blob/main/astra_vsearch_QA_for_documents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf05e3f2",
      "metadata": {
        "id": "cf05e3f2"
      },
      "source": [
        "# astra-vsearch-QA-for-documents\n",
        "This demo guides you through setting up Astra DB with Vector Search, Cassio and Open AI to implement an generative Q&A for your own Documentation\n",
        "\n",
        "Jupyter notebook for generative Q&A for douments is powered by [Astra Vector Search](https://docs.datastax.com/en/astra-serverless/docs/vector-search/overview.html) and [OpenAI](https://github.com/openai/) and Casssio [Opensource LLM integration with Cassandra and Astra DB](https://cassio.org/).\n",
        "\n",
        "## Astra Vector Search\n",
        "Astra vector search enables developers to search a database by context or meaning rather than keywords or literal values. This is done by using “embeddings”. Embeddings are a type of representation used in machine learning where high-dimensional or complex data is mapped onto vectors in a lower-dimensional space. These vectors capture the semantic properties of the input data, meaning that similar data points have similar embeddings.\n",
        "Reference: [Astra Vector Search](https://docs.datastax.com/en/astra-serverless/docs/vector-search/overview.html)\n",
        "\n",
        "## CassIO\n",
        "CassIO is the ultimate solution for seamlessly integrating Apache Cassandra® with generative artificial intelligence and other machine learning workloads. This powerful Python library simplifies the complicated process of accessing the advanced features of the Cassandra database, including vector search capabilities. With CassIO, developers can fully concentrate on designing and perfecting their AI systems without any concerns regarding the complexities of integration with Cassandra.\n",
        "Reference [Cassio](https://cassio.org/)\n",
        "\n",
        "## OpenAI\n",
        "OpenAI provides various tools and resources to implement your own Document QA Search system. This includes pre-trained language models like GPT-3.5, which can understand and generate human-like text. Additionally, OpenAI offers guidelines and APIs to leverage their models for document search and question-answering tasks, enabling developers to build powerful and intelligent Document QA Search applications.\n",
        "Reference: [OpenAI](https://github.com/openai/)\n",
        "\n",
        "## Demo Summary\n",
        "ChatGPT excels at answering questions, but only on topics it remembers from its training data. It offers you a nice dialog interface to ask questions and get answers.\n",
        "\n",
        "But what do you do when you have your onw documents? How can you leverage the GenAI and LLM models to get insights in those?\n",
        "\n",
        "Think of an Q/A Bot that you want to provide to your customers for asking questions against the documentation of your products.\n",
        "\n",
        "For beeing able to do so, you have to implement your own ChatGPT-like solution.\n",
        "The implementation requires\n",
        "1. Analysing your existing documents and store the information\n",
        "2. Providing search capabilities for your questions to get answers\n",
        "\n",
        "This is solve by using a LLM models. Ideally you embedd the data as vectors and store them in a vector database and then use the LLM models on top of that database.\n",
        "\n",
        "This notebook demonstrates a two-step Search-Ask method for enabling GPT to answer questions using a library of reference on your onw documentations based on Astra DB vector search.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "651400d1",
      "metadata": {
        "id": "651400d1"
      },
      "source": [
        "# Getting Started with this notebook\n",
        "\n",
        "These are prerequisites you need to to before running this notebook\n",
        "- Create a new vector search enabled database in Astra.\n",
        "- Create a keyspace\n",
        "- Create a token with permissions to create tables\n",
        "- Download your secure-connect-bundle.zip file\n",
        "- Create an OpenAI account and download an API Key\n",
        "\n",
        "- When you run this notebook, it will ask you for providing the secure-connect-bundle.zip, some text file and client ids, passwords as well as API Key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "311cc2e9",
      "metadata": {
        "id": "311cc2e9"
      },
      "source": [
        "# Setup\n",
        "\n",
        "This jupyter notebook was build on Colab. You need to install the following libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a6d88d66",
      "metadata": {
        "id": "a6d88d66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d23d96-a384-4971-ff8b-4e9f8dcc8bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Cloning https://github.com/hemidactylus/langchain (to revision cassio) to /tmp/pip-install-gqks0_tu/langchain_99d4c1dbd72a413fa2ad06f3756b36d5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/hemidactylus/langchain /tmp/pip-install-gqks0_tu/langchain_99d4c1dbd72a413fa2ad06f3756b36d5\n",
            "  Running command git checkout -b cassio --track origin/cassio\n",
            "  Switched to a new branch 'cassio'\n",
            "  Branch 'cassio' set up to track remote branch 'cassio' from 'origin'.\n",
            "  Resolved https://github.com/hemidactylus/langchain to commit 470af8a886a7c5a95884b2ecf72f37d68910b6b1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cassandra-driver>=3.28.0 in /usr/local/lib/python3.10/dist-packages (3.28.0)\n",
            "Requirement already satisfied: cassio>=0.0.4 in /usr/local/lib/python3.10/dist-packages (0.0.4)\n",
            "Requirement already satisfied: openai==0.27.7 in /usr/local/lib/python3.10/dist-packages (0.27.7)\n",
            "Requirement already satisfied: tiktoken==0.4.0 in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.27.7) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.7) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.27.7) (3.8.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0) (2022.10.31)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.8)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver>=3.28.0) (1.16.0)\n",
            "Requirement already satisfied: geomet<0.3,>=0.1 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver>=3.28.0) (0.2.1.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.7) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.7) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.7) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.7) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.7) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.7) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver>=3.28.0) (8.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.7) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.7) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.7) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "# install required dependencies\n",
        "! pip install \\\n",
        "    \"git+https://github.com/hemidactylus/langchain@cassio#egg=langchain\" \\\n",
        "    \"cassandra-driver>=3.28.0\" \\\n",
        "    \"cassio>=0.0.4\" \\\n",
        "    \"openai==0.27.7\" \\\n",
        "    \"tiktoken==0.4.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae20e0b5",
      "metadata": {
        "id": "ae20e0b5"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "16f9f33a",
      "metadata": {
        "id": "16f9f33a"
      },
      "outputs": [],
      "source": [
        "# Imports for our environment and accessing Astra DB\n",
        "import os\n",
        "\n",
        "import getpass\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4df2888e",
      "metadata": {
        "id": "4df2888e"
      },
      "source": [
        "# Astra DB configuration, connection bundle and token secrets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#upload secure connect bundle\n",
        "print('Please upload your Secure Connect Bundle')\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    astraBundleFileTitle = list(uploaded.keys())[0]\n",
        "    SECURE_CONNECT_BUNDLE_PATH = os.path.join(os.getcwd(), astraBundleFileTitle)\n",
        "else:\n",
        "    raise ValueError(\n",
        "        'Cannot proceed without Secure Connect Bundle. Please re-run the cell.'\n",
        "    )\n",
        "#Alternatively upload to the environment and reference it here\n",
        "#SECURE_CONNECT_BUNDLE_PATH = '/content/secure-connect-documentation.zip'\n"
      ],
      "metadata": {
        "id": "QvY0HTqm3chY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "ecef75eb-117a-482f-bf18-4c9c0a4ff3f4"
      },
      "id": "QvY0HTqm3chY",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your Secure Connect Bundle\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-46e4884e-02ec-420f-b98e-e14c04eea68a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-46e4884e-02ec-420f-b98e-e14c04eea68a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving secure-connect-documentation.zip to secure-connect-documentation (2).zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "39b4b87b",
      "metadata": {
        "id": "39b4b87b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "729a96ba-015b-4de3-b2ed-8efe07eae9e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What Astra DB token username do you want to use? ··········\n"
          ]
        }
      ],
      "source": [
        "ASTRA_DB_TOKEN_BASED_USERNAME = getpass.getpass('What Astra DB token username do you want to use? ')\n",
        "#ASTRA_DB_TOKEN_BASED_USERNAME = '<<ENTER>>'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ASTRA_DB_TOKEN_BASED_PASSWORD = getpass.getpass('What Astra DB token password do you want to use? ')\n",
        "#ASTRA_DB_TOKEN_BASED_PASSWORD = '<<ENTER>>'"
      ],
      "metadata": {
        "id": "38EAz0Kupms-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73948435-564a-4d91-a8b1-c765038d5e41"
      },
      "id": "38EAz0Kupms-",
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What Astra DB token password do you want to use? ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ASTRA_DB_KEYSPACE = input(f'Which Astra DB keypsace do you want to use? ')\n",
        "#ASTRA_DB_KEYSPACE = 'mykeyspace'"
      ],
      "metadata": {
        "id": "YZqO7R66hmMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac28b3c-442e-48eb-fd08-b9f289189192"
      },
      "id": "YZqO7R66hmMU",
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Which Astra DB keypsace do you want to use? mykeyspace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Provide Sample Data\n",
        "If you want to provide some docoments, you can upload them here.\n",
        "As a sample document you can also download some text here:"
      ],
      "metadata": {
        "id": "tyZ1IC4d3U15"
      },
      "id": "tyZ1IC4d3U15"
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve the text of a short story that will be indexed in the vector store\n",
        "! curl https://raw.githubusercontent.com/CassioML/cassio-website/main/docs/frameworks/langchain/texts/amontillado.txt --output amontillado.txt\n",
        "SAMPLEDATA_PATH=\"amontillado.txt\""
      ],
      "metadata": {
        "id": "1VsVGojG663U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b0dbd6-83ba-47a0-cb28-2b39672a77c7"
      },
      "id": "1VsVGojG663U",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 13022  100 13022    0     0  96459      0 --:--:-- --:--:-- --:--:-- 95750\r100 13022  100 13022    0     0  96459      0 --:--:-- --:--:-- --:--:-- 95750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatively you can provide your own file - please consider to customize the queries at the end of the notebook to match your content.\n",
        "#provide some sample files\n",
        "print('Please upload your own sample file:')\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    sampleDataFileTitle = list(uploaded.keys())[0]\n",
        "    SAMPLEDATA_PATH = os.path.join(os.getcwd(), sampleDataFileTitle)\n",
        "else:\n",
        "    raise ValueError(\n",
        "        'Cannot proceed without Sample Data. Please re-run the cell.'\n",
        "    )"
      ],
      "metadata": {
        "id": "PjxwchCO3n_8"
      },
      "id": "PjxwchCO3n_8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "33e090e7",
      "metadata": {
        "id": "33e090e7"
      },
      "source": [
        "# Connect to Astra DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e8c527a1",
      "metadata": {
        "id": "e8c527a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1eca4c7-4a6e-4529-89a7-d83d33656223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for cfe0851c-36a8-420c-9b15-ac1200c177c7-us-east1.db.astra.datastax.com:29042:e953f596-a31c-4699-ae7b-76a154c01d9c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for cfe0851c-36a8-420c-9b15-ac1200c177c7-us-east1.db.astra.datastax.com:29042:e953f596-a31c-4699-ae7b-76a154c01d9c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(140227095072336) cfe0851c-36a8-420c-9b15-ac1200c177c7-us-east1.db.astra.datastax.com:29042:e953f596-a31c-4699-ae7b-76a154c01d9c> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for cfe0851c-36a8-420c-9b15-ac1200c177c7-us-east1.db.astra.datastax.com:29042:e953f596-a31c-4699-ae7b-76a154c01d9c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ],
      "source": [
        "# make sure that you can connect to Astra DB - if you see errors, then have a look at the environment you configured earlier\n",
        "\n",
        "cloud_config = {\n",
        "   'secure_connect_bundle': SECURE_CONNECT_BUNDLE_PATH\n",
        "}\n",
        "auth_provider = PlainTextAuthProvider(ASTRA_DB_TOKEN_BASED_USERNAME, ASTRA_DB_TOKEN_BASED_PASSWORD)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8251382e",
      "metadata": {
        "id": "8251382e"
      },
      "source": [
        "# LLM Provider Setup\n",
        "CassIO seamlessly integrates with LangChain, offering Cassandra-specific tools for many tasks. In our example we will use vector stores, indexers, embeddings and queries.\n",
        "\n",
        "And we will use OpenAI for our LLM services. (See Pre-requisites on [cassio.org](https://cassio.org/start_here/#llm-access) for more details)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b048314c",
      "metadata": {
        "id": "b048314c"
      },
      "outputs": [],
      "source": [
        "# Set your secret(s) for LLM access:\n",
        "llmProvider = 'OpenAI'  # Be aware that you can also use 'GCP_VertexAI' with Cassio (as of date of authoring this notebook)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we will use GPT embeddings, so please provide your OpenAI AKP Key\n",
        "apiSecret = getpass.getpass('Your secret for LLM provider OpenAI: ')\n",
        "#apiSecret = \"<<ENTER>>\"\n",
        "os.environ['OPENAI_API_KEY'] = apiSecret"
      ],
      "metadata": {
        "id": "J5VPZclr6n67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ee06b8-279c-4ded-a021-ed6afd37071a"
      },
      "id": "J5VPZclr6n67",
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your secret for LLM provider OpenAI: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the needed libraries and declare the LLM model\n",
        "import langchain\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import (\n",
        "    CharacterTextSplitter,\n",
        "    RecursiveCharacterTextSplitter,\n",
        ")\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "\n",
        "\n",
        "# creation of the LLM resources\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "llm = OpenAI(temperature=0)\n",
        "myEmbedding = OpenAIEmbeddings()\n",
        "print('LLM+embeddings from OpenAI will be used.')"
      ],
      "metadata": {
        "id": "TE5pZsfs7iPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42cd60bc-be40-47b5-9de0-7ed4777977dc"
      },
      "id": "TE5pZsfs7iPT",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM+embeddings from OpenAI will be used.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vector Store on Astra DB - automatically created table and configuration\n",
        "Cassio will automatically create the needed tables and SAI in Astra DB for you. No worries about that configuration."
      ],
      "metadata": {
        "id": "ySowfxhDw3ee"
      },
      "id": "ySowfxhDw3ee"
    },
    {
      "cell_type": "code",
      "source": [
        "#define the table name to be used to store our embeddings\n",
        "ASTRA_DB_TABLE_NAME = 'vdocuments'\n",
        "cassVStore = Cassandra(\n",
        "    session=session,\n",
        "    keyspace=ASTRA_DB_KEYSPACE,\n",
        "    table_name=ASTRA_DB_TABLE_NAME,\n",
        "    embedding=myEmbedding,\n",
        ")\n",
        "\n",
        "# just in case this demo runs multiple times\n",
        "#cassVStore.clear()"
      ],
      "metadata": {
        "id": "PWC3Gu5yXHUP"
      },
      "id": "PWC3Gu5yXHUP",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creation of the DB connection\n",
        "\n",
        "index_creator = VectorstoreIndexCreator(\n",
        "    vectorstore_cls=Cassandra,\n",
        "    embedding=myEmbedding,\n",
        "    text_splitter=CharacterTextSplitter(\n",
        "        chunk_size=100,\n",
        "        chunk_overlap=0,\n",
        "    ),\n",
        "    vectorstore_kwargs={\n",
        "        'session': session,\n",
        "        'keyspace': ASTRA_DB_KEYSPACE,\n",
        "        'table_name': ASTRA_DB_TABLE_NAME,\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "abNQDp_J8eXP"
      },
      "id": "abNQDp_J8eXP",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Documents you want to process and create the embeddings to be stored in the Vector Database on Astra DB"
      ],
      "metadata": {
        "id": "IjBKFYGlzD1m"
      },
      "id": "IjBKFYGlzD1m"
    },
    {
      "cell_type": "code",
      "source": [
        "#loader = TextLoader('amontillado.txt', encoding='utf8')\n",
        "loader = TextLoader(SAMPLEDATA_PATH, encoding='utf8')"
      ],
      "metadata": {
        "id": "NEei8agU83AX"
      },
      "id": "NEei8agU83AX",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "docs = loader.load()\n",
        "subdocs = index_creator.text_splitter.split_documents(docs)\n",
        "#\n",
        "print(f'subdocument {0} ...', end=' ')\n",
        "vs = index_creator.vectorstore_cls.from_documents(\n",
        "    subdocs[:1],\n",
        "    index_creator.embedding,\n",
        "    **index_creator.vectorstore_kwargs\n",
        ")\n",
        "print('done.')\n",
        "for sdi, sd in enumerate(subdocs[1:]):\n",
        "    print(f'subdocument {sdi+1} ... out of {sd}' , end=' ')\n",
        "    vs.add_texts(texts=[sd.page_content], metadata=[sd.metadata])\n",
        "    print('done.')\n",
        "#\n",
        "index = VectorStoreIndexWrapper(vectorstore=vs)"
      ],
      "metadata": {
        "id": "_ipt6W8c-R80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "661c1234-596a-4de0-cc4a-5b730d0355f4"
      },
      "id": "_ipt6W8c-R80",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 603, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 236, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 609, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 397, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 183, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 192, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 110, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 104, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 170, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 164, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 180, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 341, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 363, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 107, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 295, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 183, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 108, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 102, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 116, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 305, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 214, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 196, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 361, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 808, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 165, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 648, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 256, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 282, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 879, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 546, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 525, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 168, which is longer than the specified 100\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 174, which is longer than the specified 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "subdocument 0 ... done.\n",
            "subdocument 1 ... out of page_content='It must be understood that neither by word nor deed had I given\\nFortunato cause to doubt my good will.  I continued, as was my wont, to\\nsmile in his face, and he did not perceive that my smile _now_ was at\\nthe thought of his immolation.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 2 ... out of page_content='He had a weak point--this Fortunato--although in other regards he was a\\nman to be respected and even feared.  He prided himself on his\\nconnoisseurship in wine.  Few Italians have the true virtuoso spirit.\\nFor the most part their enthusiasm is adopted to suit the time and\\nopportunity--to practise imposture upon the British and Austrian\\n_millionaires_.  In painting and gemmary, Fortunato, like his countrymen,\\nwas a quack--but in the matter of old wines he was sincere.  In this\\nrespect I did not differ from him materially: I was skillful in the\\nItalian vintages myself, and bought largely whenever I could.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 3 ... out of page_content='It was about dusk, one evening during the supreme madness of the\\ncarnival season, that I encountered my friend.  He accosted me with\\nexcessive warmth, for he had been drinking much.  The man wore motley.\\nHe had on a tight-fitting parti-striped dress, and his head was\\nsurmounted by the conical cap and bells.  I was so pleased to see him,\\nthat I thought I should never have done wringing his hand.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 4 ... out of page_content='I said to him--\"My dear Fortunato, you are luckily met.  How remarkably\\nwell you are looking to-day!  But I have received a pipe of what passes\\nfor Amontillado, and I have my doubts.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 5 ... out of page_content='\"How?\" said he.  \"Amontillado?  A pipe?  Impossible!  And in the middle\\nof the carnival!\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 6 ... out of page_content='\"I have my doubts,\" I replied; \"and I was silly enough to pay the full\\nAmontillado price without consulting you in the matter. You were not to\\nbe found, and I was fearful of losing a bargain.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 7 ... out of page_content='\"Amontillado!\"\\n\\n\"I have my doubts.\"\\n\\n\"Amontillado!\"\\n\\n\"And I must satisfy them.\"\\n\\n\"Amontillado!\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 8 ... out of page_content='\"As you are engaged, I am on my way to Luchesi.  If any one has a\\ncritical turn, it is he.  He will tell me--\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 9 ... out of page_content='\"Luchesi cannot tell Amontillado from Sherry.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 10 ... out of page_content='\"And yet some fools will have it that his taste is a match for your\\nown.\"\\n\\n\"Come, let us go.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 11 ... out of page_content='\"Whither?\"\\n\\n\"To your vaults.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 12 ... out of page_content='\"My friend, no; I will not impose upon your good nature.  I perceive\\nyou have an engagement.  Luchesi--\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 13 ... out of page_content='\"I have no engagement;--come.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 14 ... out of page_content='\"My friend, no.  It is not the engagement, but the severe cold with\\nwhich I perceive you are afflicted.  The vaults are insufferably damp.\\nThey are encrusted with nitre.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 15 ... out of page_content='\"Let us go, nevertheless.  The cold is merely nothing. Amontillado!\\nYou have been imposed upon.  And as for Luchesi, he cannot distinguish\\nSherry from Amontillado.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 16 ... out of page_content='Thus speaking, Fortunato possessed himself of my arm. Putting on a mask\\nof black silk, and drawing a _roquelaire_ closely about my person, I\\nsuffered him to hurry me to my palazzo.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 17 ... out of page_content='There were no attendants at home; they had absconded to make merry in\\nhonour of the time.  I had told them that I should not return until the\\nmorning, and had given them explicit orders not to stir from the house.\\nThese orders were sufficient, I well knew, to insure their immediate\\ndisappearance, one and all, as soon as my back was turned.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 18 ... out of page_content='I took from their sconces two flambeaux, and giving one to Fortunato,\\nbowed him through several suites of rooms to the archway that led into\\nthe vaults.  I passed down a long and winding staircase, requesting him\\nto be cautious as he followed. We came at length to the foot of the\\ndescent, and stood together on the damp ground of the catacombs of the\\nMontresors.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 19 ... out of page_content='The gait of my friend was unsteady, and the bells upon his cap jingled\\nas he strode.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 20 ... out of page_content='\"The pipe,\" said he.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 21 ... out of page_content='\"It is farther on,\" said I; \"but observe the white web-work which\\ngleams from these cavern walls.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 22 ... out of page_content='He turned towards me, and looked into my eyes with two filmy orbs that\\ndistilled the rheum of intoxication.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 23 ... out of page_content='\"Nitre?\" he asked, at length.\\n\\n\"Nitre,\" I replied.  \"How long have you had that cough?\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 24 ... out of page_content='\"Ugh! ugh! ugh!--ugh! ugh! ugh!--ugh! ugh! ugh!--ugh! ugh! ugh!--ugh!\\nugh! ugh!\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 25 ... out of page_content='My poor friend found it impossible to reply for many minutes.\\n\\n\"It is nothing,\" he said, at last.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 26 ... out of page_content='\"Come,\" I said, with decision, \"we will go back; your health is\\nprecious.  You are rich, respected, admired, beloved; you are happy, as\\nonce I was.  You are a man to be missed.  For me it is no matter.  We\\nwill go back; you will be ill, and I cannot be responsible.  Besides,\\nthere is Luchesi--\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 27 ... out of page_content='\"Enough,\" he said; \"the cough is a mere nothing; it will not kill me.\\nI shall not die of a cough.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 28 ... out of page_content='\"True--true,\" I replied; \"and, indeed, I had no intention of alarming\\nyou unnecessarily--but you should use all proper caution. A draught of\\nthis Medoc will defend us from the damps.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 29 ... out of page_content='Here I knocked off the neck of a bottle which I drew from a long row of\\nits fellows that lay upon the mould.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 30 ... out of page_content='\"Drink,\" I said, presenting him the wine.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 31 ... out of page_content='He raised it to his lips with a leer.  He paused and nodded to me\\nfamiliarly, while his bells jingled.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 32 ... out of page_content='\"I drink,\" he said, \"to the buried that repose around us.\"\\n\\n\"And I to your long life.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 33 ... out of page_content='He again took my arm, and we proceeded.\\n\\n\"These vaults,\" he said, \"are extensive.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 34 ... out of page_content='\"The Montresors,\" I replied, \"were a great and numerous family.\"\\n\\n\"I forget your arms.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 35 ... out of page_content='\"A huge human foot d\\'or, in a field azure; the foot crushes a serpent\\nrampant whose fangs are imbedded in the heel.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 36 ... out of page_content='\"And the motto?\"\\n\\n\"_Nemo me impune lacessit_.\"\\n\\n\"Good!\" he said.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 37 ... out of page_content='The wine sparkled in his eyes and the bells jingled.  My own fancy grew\\nwarm with the Medoc.  We had passed through walls of piled bones, with\\ncasks and puncheons intermingling, into the inmost recesses of\\ncatacombs.  I paused again, and this time I made bold to seize\\nFortunato by an arm above the elbow.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 38 ... out of page_content='\"The nitre!\" I said; \"see, it increases.  It hangs like moss upon the\\nvaults.  We are below the river\\'s bed.  The drops of moisture trickle\\namong the bones.  Come, we will go back ere it is too late.  Your\\ncough--\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 39 ... out of page_content='\"It is nothing,\" he said; \"let us go on.  But first, another draught of\\nthe Medoc.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 40 ... out of page_content='I broke and reached him a flagon of De Grave.  He emptied it at a\\nbreath.  His eyes flashed with a fierce light.  He laughed and threw\\nthe bottle upwards with a gesticulation I did not understand.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 41 ... out of page_content='I looked at him in surprise.  He repeated the movement--a grotesque one.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 42 ... out of page_content='\"You do not comprehend?\" he said.\\n\\n\"Not I,\" I replied.\\n\\n\"Then you are not of the brotherhood.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 43 ... out of page_content='\"How?\"\\n\\n\"You are not of the masons.\"\\n\\n\"Yes, yes,\" I said; \"yes, yes.\"\\n\\n\"You?  Impossible!  A mason?\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 44 ... out of page_content='\"A mason,\" I replied.\\n\\n\"A sign,\" he said, \"a sign.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 45 ... out of page_content='\"It is this,\" I answered, producing a trowel from beneath the folds of\\nmy _roquelaire_.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 46 ... out of page_content='\"You jest,\" he exclaimed, recoiling a few paces.  \"But let us proceed\\nto the Amontillado.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 47 ... out of page_content='\"Be it so,\" I said, replacing the tool beneath the cloak and again\\noffering him my arm.  He leaned upon it heavily.  We continued our\\nroute in search of the Amontillado.  We passed through a range of low\\narches, descended, passed on, and descending again, arrived at a deep\\ncrypt, in which the foulness of the air caused our flambeaux rather to\\nglow than flame.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 48 ... out of page_content='At the most remote end of the crypt there appeared another less\\nspacious.  Its walls had been lined with human remains, piled to the\\nvault overhead, in the fashion of the great catacombs of Paris.  Three\\nsides of this interior crypt were still ornamented in this manner.\\nFrom the fourth side the bones had been thrown down, and lay\\npromiscuously upon the earth, forming at one point a mound of some\\nsize.  Within the wall thus exposed by the displacing of the bones, we\\nperceived a still interior recess, in depth about four feet in width\\nthree, in height six or seven.  It seemed to have been constructed for\\nno especial use within itself, but formed merely the interval between\\ntwo of the colossal supports of the roof of the catacombs, and was\\nbacked by one of their circumscribing walls of solid granite.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 49 ... out of page_content='It was in vain that Fortunato, uplifting his dull torch, endeavoured to\\npry into the depth of the recess.  Its termination the feeble light did\\nnot enable us to see.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 50 ... out of page_content='\"Proceed,\" I said; \"herein is the Amontillado.  As for Luchesi--\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 51 ... out of page_content='\"He is an ignoramus,\" interrupted my friend, as he stepped unsteadily\\nforward, while I followed immediately at his heels.  In an instant he\\nhad reached the extremity of the niche, and finding his progress\\narrested by the rock, stood stupidly bewildered.  A moment more and I\\nhad fettered him to the granite.  In its surface were two iron staples,\\ndistant from each other about two feet, horizontally.  From one of\\nthese depended a short chain, from the other a padlock.  Throwing the\\nlinks about his waist, it was but the work of a few seconds to secure\\nit.  He was too much astounded to resist.  Withdrawing the key I\\nstepped back from the recess.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 52 ... out of page_content='\"Pass your hand,\" I said, \"over the wall; you cannot help feeling the\\nnitre.  Indeed, it is _very_ damp.  Once more let me _implore_ you to\\nreturn.  No?  Then I must positively leave you.  But I must first\\nrender you all the little attentions in my power.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 53 ... out of page_content='\"The Amontillado!\" ejaculated my friend, not yet recovered from his\\nastonishment.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 54 ... out of page_content='\"True,\" I replied; \"the Amontillado.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 55 ... out of page_content='As I said these words I busied myself among the pile of bones of which\\nI have before spoken.  Throwing them aside, I soon uncovered a quantity\\nof building stone and mortar.  With these materials and with the aid of\\nmy trowel, I began vigorously to wall up the entrance of the niche.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 56 ... out of page_content='I had scarcely laid the first tier of the masonry when I discovered\\nthat the intoxication of Fortunato had in a great measure worn off. The\\nearliest indication I had of this was a low moaning cry from the depth\\nof the recess.  It was _not_ the cry of a drunken man. There was then a\\nlong and obstinate silence.  I laid the second tier, and the third, and\\nthe fourth; and then I heard the furious vibrations of the chain.  The\\nnoise lasted for several minutes, during which, that I might hearken to\\nit with the more satisfaction, I ceased my labours and sat down upon\\nthe bones. When at last the clanking subsided, I resumed the trowel,\\nand finished without interruption the fifth, the sixth, and the seventh\\ntier.  The wall was now nearly upon a level with my breast.  I again\\npaused, and holding the flambeaux over the mason-work, threw a few\\nfeeble rays upon the figure within.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 57 ... out of page_content='A succession of loud and shrill screams, bursting suddenly from the\\nthroat of the chained form, seemed to thrust me violently back.  For a\\nbrief moment I hesitated--I trembled.  Unsheathing my rapier, I began\\nto grope with it about the recess; but the thought of an instant\\nreassured me.  I placed my hand upon the solid fabric of the catacombs,\\nand felt satisfied.  I reapproached the wall; I replied to the yells of\\nhim who clamoured.  I re-echoed--I aided--I surpassed them in volume\\nand in strength.  I did this, and the clamourer grew still.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 58 ... out of page_content='It was now midnight, and my task was drawing to a close.  I had\\ncompleted the eighth, the ninth, and the tenth tier.  I had finished a\\nportion of the last and the eleventh; there remained but a single stone\\nto be fitted and plastered in.  I struggled with its weight; I placed\\nit partially in its destined position.  But now there came from out the\\nniche a low laugh that erected the hairs upon my head.  It was\\nsucceeded by a sad voice, which I had difficulty in recognizing as that\\nof the noble Fortunato.  The voice said--' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 59 ... out of page_content='\"Ha! ha! ha!--he! he! he!--a very good joke indeed--an excellent jest.\\nWe shall have many a rich laugh about it at the palazzo--he! he!\\nhe!--over our wine--he! he! he!\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 60 ... out of page_content='\"The Amontillado!\" I said.' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 61 ... out of page_content='\"He! he! he!--he! he! he!--yes, the Amontillado.  But is it not getting\\nlate?  Will not they be awaiting us at the palazzo, the Lady Fortunato\\nand the rest?  Let us be gone.\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 62 ... out of page_content='\"Yes,\" I said, \"let us be gone.\"\\n\\n\"_For the love of God, Montresor!_\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 63 ... out of page_content='\"Yes,\" I said, \"for the love of God!\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 64 ... out of page_content='But to these words I hearkened in vain for a reply.  I grew impatient.\\nI called aloud--' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 65 ... out of page_content='\"Fortunato!\"\\n\\nNo answer.  I called again--\\n\\n\"Fortunato--\"' metadata={'source': 'amontillado.txt'} done.\n",
            "subdocument 66 ... out of page_content='No answer still.  I thrust a torch through the remaining aperture and\\nlet it fall within.  There came forth in reply only a jingling of the\\nbells.  My heart grew sick on account of the dampness of the catacombs.\\nI hastened to make an end of my labour.  I forced the last stone into\\nits position; I plastered it up.  Against the new masonry I re-erected\\nthe old rampart of bones.  For the half of a century no mortal has\\ndisturbed them.  _In pace requiescat!_' metadata={'source': 'amontillado.txt'} done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query the Vector Store to see what has been added to it and what happended with our documentation"
      ],
      "metadata": {
        "id": "87dgg1pvzT1F"
      },
      "id": "87dgg1pvzT1F"
    },
    {
      "cell_type": "code",
      "source": [
        "cqlSelect = f'SELECT * FROM {ASTRA_DB_KEYSPACE}.{ASTRA_DB_TABLE_NAME} LIMIT 3;'  # (Not a production-optimized query ...)\n",
        "rows = session.execute(cqlSelect)\n",
        "for row_i, row in enumerate(rows):\n",
        "    print(f'\\nRow {row_i}:')\n",
        "    print(f'    document_id:      {row.document_id}')\n",
        "    print(f'    embedding_vector: {str(row.embedding_vector)[:64]} ...')\n",
        "    print(f'    document:         {row.document[:64]} ...')\n",
        "    print(f'    metadata_blob:    {row.metadata_blob}')\n",
        "\n",
        "print('\\n...')"
      ],
      "metadata": {
        "id": "pepS7NSo9KRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b443644-b8e3-4ccf-a996-3bfe95e68287"
      },
      "id": "pepS7NSo9KRO",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Row 0:\n",
            "    document_id:      39d2b183da854107e6cf38c3da3d6408\n",
            "    embedding_vector: [-0.0016813528491184115, -0.011779578402638435, 0.01529727876186 ...\n",
            "    document:         \"My friend, no.  It is not the engagement, but the severe cold w ...\n",
            "    metadata_blob:    {}\n",
            "\n",
            "Row 1:\n",
            "    document_id:      3788fd3f23b30e797cc3d539e51b5d8a\n",
            "    embedding_vector: [0.005347211379557848, 8.401897503063083e-05, 0.0241224560886621 ...\n",
            "    document:         \"Nitre?\" he asked, at length.\n",
            "\n",
            "\"Nitre,\" I replied.  \"How long ha ...\n",
            "    metadata_blob:    {}\n",
            "\n",
            "Row 2:\n",
            "    document_id:      bb331c75e8d659cc73867897f1200ca6\n",
            "    embedding_vector: [-0.005720699205994606, -0.013201086781919003, 0.004768961109220 ...\n",
            "    document:         \"Let us go, nevertheless.  The cold is merely nothing. Amontilla ...\n",
            "    metadata_blob:    {}\n",
            "\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ASK - Ask Question and get Awnsers based on your documentation"
      ],
      "metadata": {
        "id": "Hc9n3zmQzgVi"
      },
      "id": "Hc9n3zmQzgVi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Search within the document contexnt for some text related information.\n",
        "query = \"Who is Luchesi?\"\n",
        "index.query(query, llm=llm)"
      ],
      "metadata": {
        "id": "Z7srVUajZw7g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6ed3b3ad-81e0-42fd-c8ae-3e5084e2f5c2"
      },
      "id": "Z7srVUajZw7g",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Luchesi is a person who is knowledgeable about wine.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Search within the document contexnt for some text un-related information.\n",
        "query = \"Who is John Doe?\"\n",
        "index.query(query, llm=llm)"
      ],
      "metadata": {
        "id": "Yl0ewjNfjQIJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "93c5ced1-2600-4a78-f4ad-5fefd38367cb"
      },
      "id": "Yl0ewjNfjQIJ",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" I don't know.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations - you just created and GenAI based Q/A Bot for you own documentation!"
      ],
      "metadata": {
        "id": "24N5yBbSzp-a"
      },
      "id": "24N5yBbSzp-a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}