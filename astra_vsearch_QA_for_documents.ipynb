{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "88c69242",
      "metadata": {
        "id": "88c69242"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/difli/astra-vsearch-image/blob/main/astra-vsearch-image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf05e3f2",
      "metadata": {
        "id": "cf05e3f2"
      },
      "source": [
        "# astra-vsearch-QA-for-documents\n",
        "This demo guides you through setting up Astra DB with Vector Search, Cassio and Open AI to implement an generative Q&A for your own Documentation\n",
        "\n",
        "Jupyter notebook for generative Q&A for douments is powered by [Astra Vector Search](https://docs.datastax.com/en/astra-serverless/docs/vector-search/overview.html) and OpenAI [(https://github.com/openai/) and Casssio [Opensource LLM integration with Cassandra and Astra DB (https://cassio.org/)].\n",
        "\n",
        "## Astra Vector Search\n",
        "Astra vector search enables developers to search a database by context or meaning rather than keywords or literal values. This is done by using “embeddings”. Embeddings are a type of representation used in machine learning where high-dimensional or complex data is mapped onto vectors in a lower-dimensional space. These vectors capture the semantic properties of the input data, meaning that similar data points have similar embeddings.\n",
        "\n",
        "\n",
        "## CassIO\n",
        "CassIO is the ultimate solution for seamlessly integrating Apache Cassandra® with generative artificial intelligence and other machine learning workloads. This powerful Python library simplifies the complicated process of accessing the advanced features of the Cassandra database, including vector search capabilities. With CassIO, developers can fully concentrate on designing and perfecting their AI systems without any concerns regarding the complexities of integration with Cassandra.\n",
        "\n",
        "## OpenAI\n",
        "OpenAI provides various tools and resources to implement your own Document QA Search system. This includes pre-trained language models like GPT-3.5, which can understand and generate human-like text. Additionally, OpenAI offers guidelines and APIs to leverage their models for document search and question-answering tasks, enabling developers to build powerful and intelligent Document QA Search applications.\n",
        "\n",
        "\n",
        "## Demo Summary\n",
        "ChatGPT excels at answering questions, but only on topics it remembers from its training data. It offers you a nice dialog interface to ask questions and get answers.\n",
        "\n",
        "But what do you do when you have your onw documents? How can you leverage the GenAI and LLM models to get insights in those?\n",
        "\n",
        "Think of an Q/A Bot that you want to provide to your customers for asking questions against the documentation of your products.\n",
        "\n",
        "For beeing able to do so, you have to implement your own ChatGPT-like solution.\n",
        "The implementation requires\n",
        "1. Analysing your existing documents and store the information\n",
        "2. Providing search capabilities for your questions to get answers\n",
        "\n",
        "This is solve by using a LLM models. Ideally you embedd the data as vectors and store them in a vector database and then use the LLM models on top of that database.\n",
        "\n",
        "This notebook demonstrates a two-step Search-Ask method for enabling GPT to answer questions using a library of reference on your onw documentations based on Astra DB Vector search.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "651400d1",
      "metadata": {
        "id": "651400d1"
      },
      "source": [
        "# Getting Started with this notebook\n",
        "\n",
        "These are prerequisites you need to to before running this notebook\n",
        "- Create a new vector search enabled database in Astra.\n",
        "- Create a keyspace\n",
        "- Create a token with permissions to create tables\n",
        "- Download your secure-connect-bundle.zip file\n",
        "- Create an OpenAI account and download an API Key\n",
        "\n",
        "- When you run this notebook, it will ask you for providing the secure-connect-bundle.zip, some text file and client ids, passwords as well as API Key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "311cc2e9",
      "metadata": {
        "id": "311cc2e9"
      },
      "source": [
        "# Setup\n",
        "\n",
        "This jupyter notebook was build on Colab. You need to install the following libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6d88d66",
      "metadata": {
        "id": "a6d88d66"
      },
      "outputs": [],
      "source": [
        "# install required dependencies\n",
        "! pip install \\\n",
        "    \"git+https://github.com/hemidactylus/langchain@cassio#egg=langchain\" \\\n",
        "    \"cassandra-driver>=3.28.0\" \\\n",
        "    \"cassio>=0.0.4\" \\\n",
        "    \"openai==0.27.7\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae20e0b5",
      "metadata": {
        "id": "ae20e0b5"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16f9f33a",
      "metadata": {
        "id": "16f9f33a"
      },
      "outputs": [],
      "source": [
        "# Imports for our environment and accessing Astra DB\n",
        "import os\n",
        "\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4df2888e",
      "metadata": {
        "id": "4df2888e"
      },
      "source": [
        "# Astra DB configuration, connection bundle and token secrets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#upload secure connect bundle\n",
        "print('Please upload your Secure Connect Bundle')\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    astraBundleFileTitle = list(uploaded.keys())[0]\n",
        "    SECURE_CONNECT_BUNDLE_PATH = os.path.join(os.getcwd(), astraBundleFileTitle)\n",
        "else:\n",
        "    raise ValueError(\n",
        "        'Cannot proceed without Secure Connect Bundle. Please re-run the cell.'\n",
        "    )\n",
        "#Alternatively upload to the environment and reference it here\n",
        "#SECURE_CONNECT_BUNDLE_PATH = '/content/secure-connect-documentation.zip'\n"
      ],
      "metadata": {
        "id": "QvY0HTqm3chY"
      },
      "id": "QvY0HTqm3chY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b4b87b",
      "metadata": {
        "id": "39b4b87b"
      },
      "outputs": [],
      "source": [
        "ASTRA_DB_TOKEN_BASED_USERNAME = input(f'What Astra DB token username do you want to use? ')\n",
        "#ASTRA_DB_TOKEN_BASED_USERNAME = '<<ENTER>>'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ASTRA_DB_TOKEN_BASED_PASSWORD = input(f'What Astra DB token password do you want to use? ')\n",
        "#ASTRA_DB_TOKEN_BASED_PASSWORD = '<<ENTER>>'"
      ],
      "metadata": {
        "id": "38EAz0Kupms-"
      },
      "id": "38EAz0Kupms-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ASTRA_DB_KEYSPACE = input(f'Which Astra DB keypsace do you want to use? ')\n",
        "#ASTRA_DB_KEYSPACE = 'mykeyspace'"
      ],
      "metadata": {
        "id": "YZqO7R66hmMU"
      },
      "id": "YZqO7R66hmMU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Provide Sample Data\n",
        "If you want to provide some docoments, you can upload them here.\n",
        "As a sample document you can also download some text here:"
      ],
      "metadata": {
        "id": "tyZ1IC4d3U15"
      },
      "id": "tyZ1IC4d3U15"
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve the text of a short story that will be indexed in the vector store\n",
        "! curl https://raw.githubusercontent.com/CassioML/cassio-website/main/docs/frameworks/langchain/texts/amontillado.txt --output amontillado.txt\n",
        "SAMPLEDATA_PATH=\"amontillado.txt\""
      ],
      "metadata": {
        "id": "1VsVGojG663U"
      },
      "id": "1VsVGojG663U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatively you can provide your own file - please consider to customize the queries at the end of the notebook to match your content.\n",
        "#provide some sample files\n",
        "print('Please upload your own sample file:')\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    sampleDataFileTitle = list(uploaded.keys())[0]\n",
        "    SAMPLEDATA_PATH = os.path.join(os.getcwd(), sampleDataFileTitle)\n",
        "else:\n",
        "    raise ValueError(\n",
        "        'Cannot proceed without Sample Data. Please re-run the cell.'\n",
        "    )"
      ],
      "metadata": {
        "id": "PjxwchCO3n_8"
      },
      "id": "PjxwchCO3n_8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "33e090e7",
      "metadata": {
        "id": "33e090e7"
      },
      "source": [
        "# Connect to Astra DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8c527a1",
      "metadata": {
        "id": "e8c527a1"
      },
      "outputs": [],
      "source": [
        "# make sure that you can connect to Astra DB - if you see errors, then have a look at the environment you configured earlier\n",
        "\n",
        "cloud_config = {\n",
        "   'secure_connect_bundle': SECURE_CONNECT_BUNDLE_PATH\n",
        "}\n",
        "auth_provider = PlainTextAuthProvider(ASTRA_DB_TOKEN_BASED_USERNAME, ASTRA_DB_TOKEN_BASED_PASSWORD)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8251382e",
      "metadata": {
        "id": "8251382e"
      },
      "source": [
        "# LLM Provider Setup\n",
        "CassIO seamlessly integrates with LangChain, offering Cassandra-specific tools for many tasks. In our example we will use vector stores, indexers, embeddings and queries.\n",
        "\n",
        "And we will use OpenAI for our LLM services. (See Pre-requisites on [cassio.org](https://cassio.org/start_here/#llm-access) for more details)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b048314c",
      "metadata": {
        "id": "b048314c"
      },
      "outputs": [],
      "source": [
        "# Set your secret(s) for LLM access:\n",
        "llmProvider = 'OpenAI'  # Be aware that you can also use 'GCP_VertexAI' with Cassio (as of date of authoring this notebook)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we will use GPT embeddings, so please provide your OpenAI AKP Key\n",
        "apiSecret = input(f'Your secret for LLM provider \"{llmProvider}\": ')\n",
        "#apiSecret = \"<<ENTER>>\"\n",
        "os.environ['OPENAI_API_KEY'] = apiSecret"
      ],
      "metadata": {
        "id": "J5VPZclr6n67"
      },
      "id": "J5VPZclr6n67",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the needed libraries and declare the LLM model\n",
        "import langchain\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import (\n",
        "    CharacterTextSplitter,\n",
        "    RecursiveCharacterTextSplitter,\n",
        ")\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "\n",
        "\n",
        "# creation of the LLM resources\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "llm = OpenAI(temperature=0)\n",
        "myEmbedding = OpenAIEmbeddings()\n",
        "print('LLM+embeddings from OpenAI will be used.')"
      ],
      "metadata": {
        "id": "TE5pZsfs7iPT"
      },
      "id": "TE5pZsfs7iPT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vector Store on Astra DB - automatically created table and configuration\n",
        "Cassio will automatically create the needed tables and SAI in Astra DB for you. No worries about that configuration."
      ],
      "metadata": {
        "id": "ySowfxhDw3ee"
      },
      "id": "ySowfxhDw3ee"
    },
    {
      "cell_type": "code",
      "source": [
        "#define the table name to be used to store our embeddings\n",
        "table_name = 'vdocuments'\n",
        "cassVStore = Cassandra(\n",
        "    session=session,\n",
        "    keyspace=ASTRA_DB_KEYSPACE,\n",
        "    table_name=table_name,\n",
        "    embedding=myEmbedding,\n",
        ")\n",
        "\n",
        "# just in case this demo runs multiple times\n",
        "#cassVStore.clear()"
      ],
      "metadata": {
        "id": "PWC3Gu5yXHUP"
      },
      "id": "PWC3Gu5yXHUP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creation of the DB connection\n",
        "\n",
        "index_creator = VectorstoreIndexCreator(\n",
        "    vectorstore_cls=Cassandra,\n",
        "    embedding=myEmbedding,\n",
        "    text_splitter=CharacterTextSplitter(\n",
        "        chunk_size=100,\n",
        "        chunk_overlap=0,\n",
        "    ),\n",
        "    vectorstore_kwargs={\n",
        "        'session': session,\n",
        "        'keyspace': ASTRA_DB_KEYSPACE,\n",
        "        'table_name': table_name,\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "abNQDp_J8eXP"
      },
      "id": "abNQDp_J8eXP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Documents you want to process and create the embeddings to be stored in the Vector Database on Astra DB"
      ],
      "metadata": {
        "id": "IjBKFYGlzD1m"
      },
      "id": "IjBKFYGlzD1m"
    },
    {
      "cell_type": "code",
      "source": [
        "#loader = TextLoader('amontillado.txt', encoding='utf8')\n",
        "loader = TextLoader(SAMPLEDATA_PATH, encoding='utf8')"
      ],
      "metadata": {
        "id": "NEei8agU83AX"
      },
      "id": "NEei8agU83AX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "docs = loader.load()\n",
        "subdocs = index_creator.text_splitter.split_documents(docs)\n",
        "#\n",
        "print(f'subdocument {0} ...', end=' ')\n",
        "vs = index_creator.vectorstore_cls.from_documents(\n",
        "    subdocs[:1],\n",
        "    index_creator.embedding,\n",
        "    **index_creator.vectorstore_kwargs\n",
        ")\n",
        "print('done.')\n",
        "for sdi, sd in enumerate(subdocs[1:]):\n",
        "    print(f'subdocument {sdi+1} ... out of {sd}' , end=' ')\n",
        "    vs.add_texts(texts=[sd.page_content], metadata=[sd.metadata])\n",
        "    print('done.')\n",
        "#\n",
        "index = VectorStoreIndexWrapper(vectorstore=vs)"
      ],
      "metadata": {
        "id": "_ipt6W8c-R80"
      },
      "id": "_ipt6W8c-R80",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query the Vector Store to see what has been added to it and what happended with our documentation"
      ],
      "metadata": {
        "id": "87dgg1pvzT1F"
      },
      "id": "87dgg1pvzT1F"
    },
    {
      "cell_type": "code",
      "source": [
        "cqlSelect = f'SELECT * FROM {keyspace}.{table_name} LIMIT 3;'  # (Not a production-optimized query ...)\n",
        "rows = session.execute(cqlSelect)\n",
        "for row_i, row in enumerate(rows):\n",
        "    print(f'\\nRow {row_i}:')\n",
        "    print(f'    document_id:      {row.document_id}')\n",
        "    print(f'    embedding_vector: {str(row.embedding_vector)[:64]} ...')\n",
        "    print(f'    document:         {row.document[:64]} ...')\n",
        "    print(f'    metadata_blob:    {row.metadata_blob}')\n",
        "\n",
        "print('\\n...')"
      ],
      "metadata": {
        "id": "pepS7NSo9KRO"
      },
      "id": "pepS7NSo9KRO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ASK - Ask Question and get Awnsers based on your documentation"
      ],
      "metadata": {
        "id": "Hc9n3zmQzgVi"
      },
      "id": "Hc9n3zmQzgVi"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is Luchesi?\"\n",
        "index.query(query, llm=llm)"
      ],
      "metadata": {
        "id": "Z7srVUajZw7g"
      },
      "id": "Z7srVUajZw7g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is John Doe?\"\n",
        "index.query(query, llm=llm)"
      ],
      "metadata": {
        "id": "Yl0ewjNfjQIJ"
      },
      "id": "Yl0ewjNfjQIJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations - you just created and GenAI based Q/A Bot for you own documentation!"
      ],
      "metadata": {
        "id": "24N5yBbSzp-a"
      },
      "id": "24N5yBbSzp-a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}